Additionally, you should create a plain text file called 'description.txt' that contains a brief summary of what your code does and any conclusions you have made from the analysis (3-5 paragraphs).

In my assignment 4, I created a recommendation system for US. national parks based on Twitter search.

In collect.py, I use 'nationalpark OR "national park" -filter:retweets' to get 5082 tweets and write them into "rawdata.txt". Then I read 59 national park names from file "national_park_list.txt", and use park names as key words to classify the 5082 tweets.  I sort the park names from most mentioned park to least mentioned park, and store the list in "save_trends.txt". Also I saved user screen_names set in file "users.txt" 

In cluster.py, I read user screen names from "users.txt", sort users by by number of frends. Select the 14 (due to the 15 rate limit) users with most friends, make a graph if "A and B have a common friend". Using 'girvan-newman' algorithm to detect communities, cut the graph into subgraphs which the number of nodes is between (30,100). The original graph is saved in file "network.png", subgraphs are saved in "i_subnetwork.png".

In classify.py, I use AFINN with 2 different models to do the recommendation. In the beginning, I read the most popular 20 parks from "save_trends.txt". Then, in the first model, I use the tweets I collected before in "collect.py" and generate the score of different national parks. While in the second model, I use the 20 park names as key words to search tweets again using Twitter API. Then I use AFINN method to calculate the average score of different parks, list the highest 10 parks as the recommendation. In the main function, I list the result of two different models. 

Conclusions:

There's a big differences between the results of two different models. I think the second model might be more accuracy because it calculate more tweets than the first one. We could see the number of tweets collected of each park in model 1 are very different. From '271'(Yosemite) to 0 (Wrangell - st. Elias and Kobuk valley). However in model 2, I tried to get approximate 200 tweets for each park. With larger data, the second model should be more accuracy.

I was surprised to see that Yellowstone National park was the only park with negative score. So I printed the negative tweets, and found out that people are scared with the news that a person is dead in the hot acid spring in Yellowstone. So that make scene to me. The tweets I could get from Twitter are limited in the passed one week, so the result are only shows the recommend national parks very recently, and easily affect by some positive and negative news.
