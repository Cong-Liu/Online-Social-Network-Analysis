{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read AFINN file:\n",
      "read 2462 AFINN terms.\n",
      "E.g.: [('apologized', -1), ('great', 3), ('joyfully', 3), ('honouring', 2), ('conciliated', 2), ('bankster', -3), ('beaten', -2), ('demand', -1), ('oxymoron', -1), ('recession', -2)]\n",
      "Top 2 most popular national parks are: \n",
      "['yosemite', 'zion', 'yellowstone', 'glacier', 'grand canyon', 'joshua tree', 'great smoky mountains', 'rocky mountain', 'arches', 'olympic', 'sequoia', 'acadia', 'shenandoah', 'badlands', 'big bend', 'bryce canyon', 'grand teton', 'everglades', 'death valley', 'redwood']\n",
      "Read 200 tweets for yosemite\n",
      "Read 298 tweets for zion\n",
      "Read 296 tweets for yellowstone\n",
      "Read 297 tweets for glacier\n",
      "Read 253 tweets for grand canyon\n",
      "Read 200 tweets for joshua tree\n",
      "Read 200 tweets for great smoky mountains\n",
      "Read 200 tweets for rocky mountain\n",
      "Read 200 tweets for arches\n",
      "Read 269 tweets for olympic\n",
      "Read 200 tweets for sequoia\n",
      "Read 212 tweets for acadia\n",
      "Read 200 tweets for shenandoah\n",
      "Read 97 tweets for badlands\n",
      "Read 200 tweets for big bend\n",
      "Read 160 tweets for bryce canyon\n",
      "Read 171 tweets for grand teton\n",
      "Read 131 tweets for everglades\n",
      "Read 123 tweets for death valley\n",
      "Read 164 tweets for redwood\n",
      "Get 4071 tweets using park name as key word:\n",
      "write 4071 to num_tweets.txt\n",
      "The top 10 recommended national parks are:\n",
      "\n",
      " score:0.504717, acadia national park\n",
      " score:0.456250, bryce canyon national park\n",
      " score:0.390244, death valley national park\n",
      " score:0.315000, great smoky mountains national park\n",
      " score:0.310000, arches national park\n",
      " score:0.310000, shenandoah national park\n",
      " score:0.310000, big bend national park\n",
      " score:0.308550, olympic national park\n",
      " score:0.306397, glacier national park\n",
      " score:0.305000, yosemite national park\n",
      " score:0.260000, rocky mountain national park\n",
      " score:0.240000, joshua tree national park\n",
      " score:0.237113, badlands national park\n",
      " score:0.216374, grand teton national park\n",
      " score:0.194631, zion national park\n",
      " score:0.190840, everglades national park\n",
      " score:0.158103, grand canyon national park\n",
      " score:0.140000, sequoia national park\n",
      " score:0.128049, redwood national park\n",
      " score:-0.003378, yellowstone national park\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from TwitterAPI import TwitterAPI, TwitterOAuth\n",
    "from collections import defaultdict\n",
    "import collect as cl\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def get_twitter():\n",
    "    \"\"\" Construct an instance of TwitterAPI using the tokens you entered above.\n",
    "    Returns:\n",
    "      An instance of TwitterAPI.\n",
    "    \"\"\"\n",
    "    o = TwitterOAuth.read_file('credentials.txt')\n",
    "    # Using OAuth1...\n",
    "    twitter = TwitterAPI(o.consumer_key,\n",
    "                         o.consumer_secret,\n",
    "                         o.access_token_key,\n",
    "                         o.access_token_secret)\n",
    "    return twitter\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "# Download the AFINN lexicon, unzip, and read the latest word list in AFINN-111.txt\n",
    "\n",
    "def get_afinn():\n",
    "    url = urlopen('http://www2.compute.dtu.dk/~faan/data/AFINN.zip')\n",
    "    zipfile = ZipFile(BytesIO(url.read()))\n",
    "    afinn_file = zipfile.open('AFINN/AFINN-111.txt')\n",
    "\n",
    "    afinn = dict()\n",
    "\n",
    "    for line in afinn_file:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2:\n",
    "            afinn[parts[0].decode(\"utf-8\")] = int(parts[1])\n",
    "\n",
    "    print('read %d AFINN terms.\\nE.g.: %s' % (len(afinn), str(list(afinn.items())[:10])))\n",
    "    return afinn\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "# afinn = get_afinn()\n",
    "def afinn_sentiment(terms, afinn):\n",
    "    total = 0.\n",
    "    for t in terms:\n",
    "        if t in afinn:\n",
    "            #             print('\\t%s=%d' % (t, afinn[t]))\n",
    "            total += afinn[t]\n",
    "    return total\n",
    "\n",
    "\n",
    "# doc = \"i don't know if this is a scam or if mine was broken\".split()\n",
    "# print('AFINN: ', afinn_sentiment(doc, afinn))\n",
    "\n",
    "def robust_request(twitter, resource, params, max_tries=5):\n",
    "    for i in range(max_tries):\n",
    "        request = twitter.request(resource, params)\n",
    "        if request.status_code == 200:\n",
    "            return request\n",
    "        else:\n",
    "            print('Got error %s \\nsleeping for 15 minutes.' % request.text)\n",
    "            sys.stderr.flush()\n",
    "            time.sleep(61 * 15)\n",
    "\n",
    "\n",
    "# In[98]:\n",
    "\n",
    "# fn = 'save_trends.txt'\n",
    "def get_park_list(filename, top=20):\n",
    "    f = open(filename)\n",
    "    da = f.readlines()\n",
    "    data = [l.strip('\\n') for l in da]\n",
    "    return data[:top]\n",
    "\n",
    "\n",
    "def get_data(park_list):\n",
    "    datatable = cl.get_data_from_file(filename='save_tweets.txt')\n",
    "    p_nums, parks = cl.get_park_trend(park_list, datatable)\n",
    "    return p_nums, parks\n",
    "\n",
    "\n",
    "def get_list(p_nums):\n",
    "    park_list = []\n",
    "    for i, r in enumerate(p_nums):\n",
    "        park_list.append(r[0])\n",
    "    return park_list\n",
    "\n",
    "\n",
    "# p_nums, parks = get_data()\n",
    "# park_list = get_list(p_nums)\n",
    "\n",
    "\n",
    "# In[132]:\n",
    "\n",
    "def get_tweets_helper(name, max_len=200):\n",
    "    twitter = get_twitter()\n",
    "    tweets = []\n",
    "    m_id = 0 if len(tweets) is 0 else tweets[len(tweets) - 1]['id']\n",
    "    quary = name + ' national park OR \"' + name + 'nationalpark\"-filter:retweets'\n",
    "\n",
    "    while len(tweets) < max_len:\n",
    "        rid = m_id\n",
    "        m_id = 0 if len(tweets) is 0 else tweets[len(tweets) - 1]['id']\n",
    "        for r in robust_request(twitter, 'search/tweets', {'q': quary, 'country': 'United States', 'lang': 'en',\n",
    "                                                           'count': 100, 'max_id': m_id}):\n",
    "            #         for r in twitter.request('search/tweets', {'q':  quary, 'country': 'United States', 'lang': 'en',\n",
    "            #                                                    'count':100, 'max_id': m_id}):\n",
    "\n",
    "            if r['id'] == rid:\n",
    "                print('Read %d tweets for %s' % (len(tweets), name))\n",
    "                return tweets\n",
    "            tweets.append(r)\n",
    "\n",
    "    print('Read %d tweets for %s' % (len(tweets), name))\n",
    "    return tweets\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "def get_tweets(park_list):\n",
    "    park_tweets = defaultdict()\n",
    "    num_tweets = 0\n",
    "    fw = open('class.txt', 'a')\n",
    "    for name in park_list:\n",
    "        t = get_tweets_helper(name)\n",
    "        park_tweets[name] = t\n",
    "        num_tweets += len(t)\n",
    "        fw.write('\\n%d\\t%s\\t' % (len(t), name))\n",
    "        print(t[0], file=fw)\n",
    "\n",
    "    return (park_tweets, num_tweets)\n",
    "\n",
    "\n",
    "# In[121]:\n",
    "\n",
    "def get_score_from_new_tweets(afinn, park_list, park_tweets):\n",
    "    park_afinn = defaultdict(lambda: 0)\n",
    "    for n in park_list:\n",
    "        tweets = park_tweets[n]\n",
    "        if len(tweets) is not 0:\n",
    "            score = 0\n",
    "            for t in tweets:\n",
    "                score += afinn_sentiment(t['text'].split(), afinn)\n",
    "            park_afinn[n] = score / len(tweets)\n",
    "    return sorted(park_afinn.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "# In[104]:\n",
    "\n",
    "def get_score(afinn, park_list, parks):\n",
    "    park_afinn = defaultdict(lambda: 0)\n",
    "    for n in park_list[:20]:\n",
    "        tweets = parks[n]\n",
    "        if len(tweets) is not 0:\n",
    "            score = 0\n",
    "            for t in tweets:\n",
    "                score += afinn_sentiment(t.split(), afinn)\n",
    "            park_afinn[n] = score / len(tweets)\n",
    "    return sorted(park_afinn.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def save_nums(fn, nums):\n",
    "    rawData = open(fn, 'a')\n",
    "    rawData.write('%d\\n' % nums)\n",
    "    print('write %d to %s' % (nums, fn))\n",
    "    rawData.close()\n",
    "\n",
    "\n",
    "# In[122]:\n",
    "\n",
    "def main():\n",
    "    print('Read AFINN file:')\n",
    "    afinn = get_afinn()\n",
    "    park_list = get_park_list('save_trends.txt', 20)\n",
    "\n",
    "    print('Top 2 most popular national parks are: ')\n",
    "    print(park_list)\n",
    "\n",
    "    # model 1 using tweets collected from collect.py\n",
    "    print('\\nModel 1: Using data collected before:')\n",
    "    p_nums, parks = get_data(park_list)\n",
    "    result = get_score(afinn, park_list, parks)\n",
    "    print('The top 10 recommended national parks are:\\n')\n",
    "    for r in result[:10]:\n",
    "        print(' score:%f, %s national park' % (r[1], r[0]))\n",
    "\n",
    "    # model 2 using new tweets collected according to top 20 parks' names\n",
    "    print('\\nModel 2: Using new tweets collected from Twitter:')\n",
    "    park_tweets, num_tweets = get_tweets(park_list)\n",
    "    print('Get %d tweets using park name as key word:' % num_tweets)\n",
    "    save_nums('num_tweets.txt', num_tweets)\n",
    "    result2 = get_score_from_new_tweets(afinn, park_list, park_tweets)\n",
    "    print('The top 10 recommended national parks are:\\n')\n",
    "    for r in result2:\n",
    "        print(' score:%f, %s national park' % (r[1], r[0]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read AFINN file:\n",
      "read 2462 AFINN terms.\n",
      "E.g.: [('apologized', -1), ('great', 3), ('joyfully', 3), ('honouring', 2), ('conciliated', 2), ('bankster', -3), ('beaten', -2), ('demand', -1), ('oxymoron', -1), ('recession', -2)]\n",
      "Top 10 most popular national parks are: \n",
      "['yosemite', 'zion', 'yellowstone', 'glacier', 'grand canyon', 'joshua tree', 'great smoky mountains', 'rocky mountain', 'arches', 'olympic', 'sequoia', 'acadia', 'shenandoah', 'badlands', 'big bend']\n",
      "\n",
      "Model 1: Using data collected before:\n",
      "The top 10 recommended national parks are:\n",
      "\n",
      " score:3.746032, great smoky mountains national park\n",
      " score:3.368421, grand canyon national park\n",
      " score:1.500000, big bend national park\n",
      " score:0.802469, arches national park\n",
      " score:0.748408, yosemite national park\n",
      " score:0.693878, olympic national park\n",
      " score:0.652174, sequoia national park\n",
      " score:0.650602, rocky mountain national park\n",
      " score:0.586207, shenandoah national park\n",
      " score:0.517241, badlands national park\n",
      "\n",
      "Model 2: Using new tweets collected from Twitter:\n",
      "Read 200 tweets for yosemite\n",
      "Read 297 tweets for zion\n",
      "Read 296 tweets for yellowstone\n",
      "Read 297 tweets for glacier\n",
      "Read 253 tweets for grand canyon\n",
      "Read 200 tweets for joshua tree\n",
      "Read 200 tweets for great smoky mountains\n",
      "Read 200 tweets for rocky mountain\n",
      "Read 200 tweets for arches\n",
      "Read 269 tweets for olympic\n",
      "Read 200 tweets for sequoia\n",
      "Read 212 tweets for acadia\n",
      "Read 200 tweets for shenandoah\n",
      "not enough data\n",
      "Read 97 tweets for badlands\n",
      "Read 200 tweets for big bend\n",
      "Get 3321 tweets using park name as key word:\n",
      "write 3321 to num_tweets.txt\n",
      "The top 10 recommended national parks are:\n",
      "\n",
      " score:0.504717, acadia national park\n",
      " score:0.315000, great smoky mountains national park\n",
      " score:0.310000, shenandoah national park\n",
      " score:0.310000, big bend national park\n",
      " score:0.308550, olympic national park\n",
      " score:0.306397, glacier national park\n",
      " score:0.305000, yosemite national park\n",
      " score:0.295000, arches national park\n",
      " score:0.260000, rocky mountain national park\n",
      " score:0.240000, joshua tree national park\n"
     ]
    }
   ],
   "source": [
    "print('Read AFINN file:')\n",
    "afinn = get_afinn()\n",
    "park_list =  get_park_list('save_trends.txt',15)\n",
    "# park_list = ['badlands','yosemite']\n",
    "print ('Top 10 most popular national parks are: ')\n",
    "print(park_list)\n",
    "\n",
    "#model 1 using tweets collected from collect.py\n",
    "print('\\nModel 1: Using data collected before:')\n",
    "p_nums, parks = get_data()\n",
    "result = get_score(afinn, park_list, parks)\n",
    "print('The top 10 recommended national parks are:\\n')\n",
    "for r in result[:10]:\n",
    "    print(' score:%f, %s national park'%(r[1], r[0]))\n",
    "\n",
    "#model 2 using new tweets collected according to top 20 parks' names\n",
    "print('\\nModel 2: Using new tweets collected from Twitter:')\n",
    "park_tweets, num_tweets= get_tweets(park_list)\n",
    "print('Get %d tweets using park name as key word:' % num_tweets)\n",
    "save_nums('num_tweets.txt', num_tweets)\n",
    "result2 = get_score_from_new_tweets(afinn, park_list,park_tweets)\n",
    "print('The top 10 recommended national parks are:\\n')\n",
    "for r in result2:\n",
    "    print(' score:%f, %s national park'%(r[1], r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " score:0.504717, acadia national park\n",
      " score:0.315000, great smoky mountains national park\n",
      " score:0.310000, shenandoah national park\n",
      " score:0.310000, big bend national park\n",
      " score:0.308550, olympic national park\n",
      " score:0.306397, glacier national park\n",
      " score:0.305000, yosemite national park\n",
      " score:0.295000, arches national park\n",
      " score:0.260000, rocky mountain national park\n",
      " score:0.240000, joshua tree national park\n",
      " score:0.237113, badlands national park\n",
      " score:0.195286, zion national park\n",
      " score:0.158103, grand canyon national park\n",
      " score:0.140000, sequoia national park\n",
      " score:-0.003378, yellowstone national park\n"
     ]
    }
   ],
   "source": [
    "for r in result2:\n",
    "    print(' score:%f, %s national park'%(r[1], r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
